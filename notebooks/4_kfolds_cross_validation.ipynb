{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../data/raw/test.csv\")\n",
    "submission = pd.read_csv(\"../data/raw/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "target = \"NObeyesdad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",  # Objective function for the model\n",
    "    \"metric\": \"multi_logloss\",  # Evaluation metric\n",
    "    \"verbosity\": -1,  # Verbosity level (-1 for silent)\n",
    "    \"boosting_type\": \"gbdt\",  # Gradient boosting type\n",
    "    \"random_state\": 0,  # Random state for reproducibility\n",
    "    \"num_class\": 7,  # Number of classes in the dataset\n",
    "    \"learning_rate\": 0.012895148872894106,  # Learning rate for gradient boosting\n",
    "    \"n_estimators\": 457,  # Number of boosting iterations\n",
    "    \"lambda_l1\": 0.008179204992451842,  # L1 regularization term\n",
    "    \"lambda_l2\": 0.022669285325135756,  # L2 regularization term\n",
    "    \"max_depth\": 12,  # Maximum depth of the trees\n",
    "    \"colsample_bytree\": 0.4240998469631964,  # Fraction of features to consider for each tree\n",
    "    \"subsample\": 0.9658150639983177,  # Fraction of samples to consider for each boosting iteration\n",
    "    \"min_child_samples\": 46,  # Minimum number of data needed in a leaf\n",
    "    \"njobs\": -1,  # Number of parallel threads\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [c for c in df.columns if c not in (\"id\", target, \"kfold\")]\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=[object]).columns.tolist()\n",
    "categorical_columns.remove(target)\n",
    "\n",
    "df_test = df_test[useful_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9089595375722543\n",
      "1 0.903179190751445\n",
      "2 0.9130539499036608\n",
      "3 0.9103830402312696\n",
      "4 0.9111057576487593\n"
     ]
    }
   ],
   "source": [
    "final_predictions = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold in range(5):\n",
    "    x_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    x_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    x_test = df_test.copy()\n",
    "\n",
    "    y_train = x_train[target]\n",
    "    y_valid = x_valid[target]\n",
    "\n",
    "    x_train = x_train[useful_features]\n",
    "    x_valid = x_valid[useful_features]\n",
    "\n",
    "    x_train = pd.get_dummies(x_train, columns=categorical_columns, drop_first=True)\n",
    "    x_valid = pd.get_dummies(x_valid, columns=categorical_columns, drop_first=True)\n",
    "    x_test = pd.get_dummies(x_test, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "    # Align the DataFrames by the columns\n",
    "    x_test, x_train = x_test.align(x_train, join=\"left\", axis=1)\n",
    "    x_test, x_valid = x_test.align(x_valid, join=\"left\", axis=1)\n",
    "\n",
    "    # Fill the missing values with 0\n",
    "    x_train.fillna(0, inplace=True)\n",
    "    x_valid.fillna(0, inplace=True)\n",
    "\n",
    "    lgbm_classifier = LGBMClassifier(**params)\n",
    "    lgbm_classifier.fit(x_train, y_train)\n",
    "\n",
    "    preds_valid = lgbm_classifier.predict(x_valid)\n",
    "    preds_test = lgbm_classifier.predict(x_test)\n",
    "\n",
    "    final_predictions.append(preds_test)\n",
    "    accuracy_scores.append(accuracy_score(y_valid, preds_valid))\n",
    "    print(fold, accuracy_score(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9093362952214779\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the list of lists to group predictions for each data point across folds\n",
    "transposed_predictions = list(map(list, zip(*final_predictions)))\n",
    "\n",
    "# Initialize an empty list to store the mode of predictions for each data point\n",
    "final_mode_predictions = []\n",
    "\n",
    "# Iterate over the grouped predictions for each data point\n",
    "for predictions in transposed_predictions:\n",
    "    # Use np.unique to count occurrences of each category and find the mode\n",
    "    values, counts = np.unique(predictions, return_counts=True)\n",
    "    index = np.argmax(counts)  # Index of the most frequent element\n",
    "    mode_prediction = values[index]  # The most frequent element\n",
    "    final_mode_predictions.append(mode_prediction)\n",
    "\n",
    "# final_mode_predictions now contains the mode prediction for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[target] = final_mode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\n",
    "    \"../data/submissions/submission2_lgbm_no_feature_eng_kfolds.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obesity-multi-class-prediction-bFHmIcF9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
